{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hierarchical Bayesian Modeling for Creator Experiments\n",
    "\n",
    "## The Problem\n",
    "\n",
    "We run A/B experiments on individual creators. Many creators have **small sample sizes** (few hundred users or fewer), making individual estimates noisy and unreliable.\n",
    "\n",
    "**Example**: A creator with 80 users might show a treatment effect of +$1.50 ± $3.00. That's useless!\n",
    "\n",
    "## The Solution: Hierarchical Bayesian Modeling (HBM)\n",
    "\n",
    "We can **borrow strength** from similar creators (grouped by genre) to improve small-sample estimates through **partial pooling**.\n",
    "\n",
    "This notebook demonstrates:\n",
    "1. Why standard (\"no pooling\") estimates fail for small creators\n",
    "2. How HBM produces better estimates through partial pooling\n",
    "3. Quantitative validation that HBM recovers ground truth\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Add src to path\n",
    "sys.path.append('../')\n",
    "\n",
    "from src.data_generation import generate_experiment_data, summarize_data\n",
    "from src.frequentist import no_pooling_estimates, complete_pooling_estimates\n",
    "from src.hierarchical_model import (\n",
    "    prepare_creator_summaries,\n",
    "    fit_hierarchical_model,\n",
    "    extract_hbm_estimates,\n",
    "    extract_genre_estimates,\n",
    "    check_mcmc_diagnostics\n",
    ")\n",
    "from src.validation import (\n",
    "    compare_all_methods,\n",
    "    stratified_comparison,\n",
    "    compute_shrinkage_metrics,\n",
    "    validate_genre_recovery\n",
    ")\n",
    "from src.visualization import (\n",
    "    plot_shrinkage,\n",
    "    plot_mse_comparison,\n",
    "    plot_coverage_vs_width,\n",
    "    plot_individual_creators,\n",
    "    plot_genre_recovery,\n",
    "    plot_posterior_distributions,\n",
    "    plot_trace\n",
    ")\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.precision', 3)\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"✓ All imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Generate Synthetic Data\n",
    "\n",
    "We use synthetic data with **known ground truth** so we can definitively measure which method works best.\n",
    "\n",
    "### Data Generating Process\n",
    "\n",
    "```\n",
    "Hierarchy:\n",
    "  Platform\n",
    "    ↓\n",
    "  Genres (5 types: comedy, music, gaming, etc.)\n",
    "    ↓\n",
    "  Creators (100 per genre = 500 total)\n",
    "    ↓\n",
    "  Users (highly variable: 30-5000 per creator)\n",
    "```\n",
    "\n",
    "Each creator has a **true treatment effect** that varies around their genre's mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic data\n",
    "df, truth = generate_experiment_data(seed=42)\n",
    "\n",
    "# Print summary\n",
    "summarize_data(df, truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sample size distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Sample size histogram\n",
    "creator_sizes = df.groupby('creator_id').size()\n",
    "axes[0].hist(creator_sizes, bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[0].set_xlabel('Sample Size per Creator', fontweight='bold')\n",
    "axes[0].set_ylabel('Number of Creators', fontweight='bold')\n",
    "axes[0].set_title('Sample Size Distribution\\n(Many small creators!)', fontweight='bold')\n",
    "axes[0].axvline(100, color='red', linestyle='--', linewidth=2, label='n=100')\n",
    "axes[0].axvline(500, color='orange', linestyle='--', linewidth=2, label='n=500')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# True creator effects by genre\n",
    "effect_by_genre = pd.DataFrame({\n",
    "    'creator_id': range(len(truth['creator_effects'])),\n",
    "    'genre_idx': truth['creator_genre'],\n",
    "    'true_effect': truth['creator_effects']\n",
    "})\n",
    "effect_by_genre['genre'] = effect_by_genre['genre_idx'].map(\n",
    "    {i: name for i, name in enumerate(truth['genre_names'])}\n",
    ")\n",
    "\n",
    "sns.violinplot(data=effect_by_genre, x='genre', y='true_effect', ax=axes[1])\n",
    "axes[1].set_xlabel('Genre', fontweight='bold')\n",
    "axes[1].set_ylabel('True Treatment Effect', fontweight='bold')\n",
    "axes[1].set_title('True Effects Vary by Genre\\n(This is what we want to recover)', fontweight='bold')\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Frequentist Baselines\n",
    "\n",
    "### No Pooling (Standard Approach)\n",
    "Analyze each creator independently. **Unbiased but high variance** for small creators.\n",
    "\n",
    "### Complete Pooling\n",
    "Use only genre-level averages. **Low variance but high bias** (ignores individual variation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute frequentist estimates\n",
    "print(\"Computing no-pooling estimates...\")\n",
    "no_pool = no_pooling_estimates(df)\n",
    "\n",
    "print(\"Computing complete-pooling estimates...\")\n",
    "complete_pool = complete_pooling_estimates(df)\n",
    "\n",
    "print(\"\\n✓ Baseline estimates computed!\")\n",
    "\n",
    "# Quick look at no-pooling for small creators\n",
    "small_creators = no_pool[no_pool['n_total'] < 100].head(10)\n",
    "print(\"\\nNo-pooling estimates for small creators:\")\n",
    "print(small_creators[['creator_id', 'n_total', 'effect_hat', 'se', 'ci_lower', 'ci_upper']])\n",
    "print(\"\\nNotice: Huge uncertainty (wide CIs) for small creators!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Fit Hierarchical Bayesian Model\n",
    "\n",
    "The HBM implements **partial pooling**: estimates are shrunk toward their genre mean, with more shrinkage for noisier (smaller-n) estimates.\n",
    "\n",
    "### Model Specification\n",
    "\n",
    "```\n",
    "mu_global ~ Normal(0, 1)                    # Platform-level mean\n",
    "sigma_genre ~ HalfNormal(1)                 # Between-genre variance\n",
    "\n",
    "mu_genre[g] ~ Normal(mu_global, sigma_genre)  # Genre effects\n",
    "\n",
    "sigma_creator ~ HalfNormal(1)               # Within-genre variance\n",
    "tau[i] ~ Normal(mu_genre[g_i], sigma_creator)  # Creator effects\n",
    "\n",
    "observed_effect[i] ~ Normal(tau[i], SE[i])  # Likelihood\n",
    "```\n",
    "\n",
    "We use **PyMC** with the NUTS sampler (No-U-Turn Sampler, a variant of Hamiltonian Monte Carlo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare summary statistics for HBM\n",
    "print(\"Preparing creator summary statistics...\")\n",
    "creator_summaries = prepare_creator_summaries(df)\n",
    "print(f\"✓ Prepared summaries for {len(creator_summaries)} creators\")\n",
    "\n",
    "# Fit the hierarchical model\n",
    "print(\"\\nFitting hierarchical Bayesian model...\")\n",
    "print(\"(This may take 2-5 minutes)\\n\")\n",
    "\n",
    "idata = fit_hierarchical_model(\n",
    "    creator_summaries,\n",
    "    n_genres=truth['n_genres'],\n",
    "    draws=2000,\n",
    "    tune=1000,\n",
    "    chains=4,\n",
    "    random_seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check MCMC diagnostics\n",
    "# CRITICAL: Must verify sampling worked before trusting results!\n",
    "diagnostics = check_mcmc_diagnostics(idata, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract estimates from posterior\n",
    "print(\"Extracting HBM estimates...\")\n",
    "hbm = extract_hbm_estimates(idata, creator_summaries)\n",
    "genre_est = extract_genre_estimates(idata, truth['n_genres'])\n",
    "\n",
    "print(f\"✓ Extracted estimates for {len(hbm)} creators\")\n",
    "\n",
    "# Look at HBM estimates for the same small creators\n",
    "small_creator_ids = no_pool[no_pool['n_total'] < 100].head(10)['creator_id'].values\n",
    "small_hbm = hbm[hbm['creator_id'].isin(small_creator_ids)]\n",
    "\n",
    "print(\"\\nHBM estimates for small creators:\")\n",
    "print(small_hbm[['creator_id', 'n_total', 'effect_hat', 'se', 'ci_lower', 'ci_upper']])\n",
    "print(\"\\nNotice: Much narrower CIs than no-pooling!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. The Key Visualization: Shrinkage Plot\n",
    "\n",
    "This plot shows **how HBM works**:\n",
    "- x-axis: No-pooling (frequentist) estimate\n",
    "- y-axis: HBM estimate\n",
    "- Point size: sample size (larger = more data)\n",
    "- Color: genre\n",
    "\n",
    "**What to look for**:\n",
    "- Small creators (small points) are pulled away from y=x line toward their genre mean\n",
    "- Large creators (large points) stay near y=x line (data dominates prior)\n",
    "- This is **partial pooling** in action!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_shrinkage(no_pool, hbm, truth, save_path='../outputs/shrinkage_plot.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Quantitative Comparison\n",
    "\n",
    "Since we have **ground truth**, we can definitively measure which method works best.\n",
    "\n",
    "### Metrics:\n",
    "1. **MSE (Mean Squared Error)**: How close are estimates to the truth?\n",
    "2. **Coverage**: Do 95% intervals contain the true value 95% of the time?\n",
    "3. **Interval Width**: Narrower is better (if coverage is maintained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall comparison\n",
    "overall_results = compare_all_methods(no_pool, complete_pool, hbm, truth, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratified comparison (by sample size)\n",
    "stratified_results = stratified_comparison(\n",
    "    no_pool, complete_pool, hbm, truth,\n",
    "    bins=[0, 100, 500, np.inf],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSE comparison plot\n",
    "fig = plot_mse_comparison(no_pool, complete_pool, hbm, truth,\n",
    "                         save_path='../outputs/mse_comparison.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coverage vs. width trade-off\n",
    "fig = plot_coverage_vs_width(no_pool, complete_pool, hbm, truth,\n",
    "                            save_path='../outputs/coverage_vs_width.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Individual Creator Examples\n",
    "\n",
    "Let's look at specific examples to make the improvement tangible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_individual_creators(no_pool, hbm, truth, n_examples=12,\n",
    "                              save_path='../outputs/individual_creators.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Genre-Level Recovery\n",
    "\n",
    "Does HBM correctly recover the genre-level structure?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate genre recovery\n",
    "genre_validation = validate_genre_recovery(genre_est, truth, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot genre recovery\n",
    "fig = plot_genre_recovery(genre_est, truth, save_path='../outputs/genre_recovery.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Hyperparameter Recovery\n",
    "\n",
    "Can the model recover the variance parameters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_posterior_distributions(idata, truth, save_path='../outputs/posteriors.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. MCMC Diagnostics\n",
    "\n",
    "Trace plots to verify the sampler is working correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_trace(idata, save_path='../outputs/trace_plots.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Shrinkage Analysis\n",
    "\n",
    "Quantify how much HBM shrinks estimates, and verify it shrinks small creators more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shrinkage = compute_shrinkage_metrics(no_pool, hbm, truth)\n",
    "\n",
    "# Plot shrinkage vs. sample size\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "ax.scatter(shrinkage['n_total'], shrinkage['shrinkage_pct'],\n",
    "          alpha=0.5, s=30, edgecolors='white', linewidth=0.5)\n",
    "ax.set_xlabel('Sample Size', fontweight='bold')\n",
    "ax.set_ylabel('Shrinkage (as % of deviation from genre mean)', fontweight='bold')\n",
    "ax.set_title('Shrinkage vs. Sample Size\\nSmall creators are shrunk more', fontweight='bold', fontsize=14)\n",
    "ax.set_xscale('log')\n",
    "ax.axhline(0, color='black', linestyle='-', linewidth=1, alpha=0.3)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/shrinkage_vs_size.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\nShrinkage by size bin:\")\n",
    "shrinkage['size_bin'] = pd.cut(shrinkage['n_total'], bins=[0, 100, 500, np.inf],\n",
    "                               labels=['Small (<100)', 'Medium (100-500)', 'Large (>500)'])\n",
    "print(shrinkage.groupby('size_bin')['shrinkage_pct'].agg(['mean', 'median']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Summary & Conclusions\n",
    "\n",
    "### Key Findings:\n",
    "\n",
    "1. **HBM achieves lower MSE than both baselines**, especially for small creators\n",
    "2. **HBM maintains ~95% coverage** (well-calibrated intervals)\n",
    "3. **HBM has narrower intervals** than no-pooling while maintaining coverage\n",
    "4. **Shrinkage is adaptive**: more for small creators, less for large creators\n",
    "5. **Genre-level structure is recovered** accurately\n",
    "\n",
    "### When to use HBM:\n",
    "- ✅ Many entities with variable sample sizes\n",
    "- ✅ Natural grouping structure (genres, segments, etc.)\n",
    "- ✅ Need stable estimates for small entities\n",
    "- ✅ Willing to assume entities within groups are \"exchangeable\"\n",
    "\n",
    "### When NOT to use HBM:\n",
    "- ❌ All entities have large sample sizes (no pooling works fine)\n",
    "- ❌ No meaningful grouping structure\n",
    "- ❌ Groups have completely different mechanisms (not exchangeable)\n",
    "\n",
    "### Practical Considerations:\n",
    "- **Computation**: ~2-5 minutes for 500 creators (fast enough for batch processing)\n",
    "- **Validation**: Always check MCMC diagnostics (R-hat, ESS, divergences)\n",
    "- **Communication**: Explain shrinkage to stakeholders (\"we borrow strength from similar creators\")\n",
    "\n",
    "---\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "Potential extensions:\n",
    "1. **Non-normal outcomes**: Revenue is skewed → try log-transform or hurdle model\n",
    "2. **Multiple groupings**: Crossed effects (genre × audience segment)\n",
    "3. **Time-varying effects**: Account for temporal trends\n",
    "4. **Production deployment**: Use variational inference for faster inference\n",
    "5. **Informative priors**: Use historical experiment data to set priors\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix: Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save comparison table\n",
    "comparison_df = pd.DataFrame({\n",
    "    'creator_id': no_pool['creator_id'],\n",
    "    'genre': no_pool['genre'],\n",
    "    'n_total': no_pool['n_total'],\n",
    "    'true_effect': truth['creator_effects'],\n",
    "    'no_pool_est': no_pool['effect_hat'],\n",
    "    'no_pool_ci_width': no_pool['ci_upper'] - no_pool['ci_lower'],\n",
    "    'complete_pool_est': complete_pool['effect_hat'],\n",
    "    'hbm_est': hbm['effect_hat'],\n",
    "    'hbm_ci_width': hbm['ci_upper'] - hbm['ci_lower']\n",
    "})\n",
    "\n",
    "comparison_df['no_pool_error'] = comparison_df['no_pool_est'] - comparison_df['true_effect']\n",
    "comparison_df['hbm_error'] = comparison_df['hbm_est'] - comparison_df['true_effect']\n",
    "\n",
    "comparison_df.to_csv('../outputs/comparison_results.csv', index=False)\n",
    "print(\"✓ Results saved to outputs/comparison_results.csv\")\n",
    "\n",
    "# Save overall metrics\n",
    "overall_results.to_csv('../outputs/overall_metrics.csv', index=False)\n",
    "print(\"✓ Overall metrics saved to outputs/overall_metrics.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
